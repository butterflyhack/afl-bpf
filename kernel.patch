diff --git a/arch/arm/net/bpf_jit_32.c b/arch/arm/net/bpf_jit_32.c
index 591f9db3bf40..702c7830dcb3 100644
--- a/arch/arm/net/bpf_jit_32.c
+++ b/arch/arm/net/bpf_jit_32.c
@@ -8,6 +8,9 @@
  * Free Software Foundation; version 2 of the License.
  */
 
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/bitops.h>
 #include <linux/compiler.h>
 #include <linux/errno.h>
@@ -74,6 +77,7 @@ struct jit_ctx {
 
 int bpf_jit_enable __read_mostly;
 
+#ifdef __arm__
 static inline int call_neg_helper(struct sk_buff *skb, int offset, void *ret,
 		      unsigned int size)
 {
@@ -137,6 +141,12 @@ static u32 jit_mod(u32 dividend, u32 divisor)
 {
 	return dividend % divisor;
 }
+#else
+#undef skb_get_poff
+
+extern u8 jit_udiv[], jit_mod[], skb_get_poff[];
+extern u8 jit_get_skb_b[], jit_get_skb_h[], jit_get_skb_w[];
+#endif
 
 static inline void _emit(int cond, u32 inst, struct jit_ctx *ctx)
 {
@@ -998,6 +1008,9 @@ b_epilogue:
 	return 0;
 }
 
+#ifdef __BPF_TEST
+size_t bpf_emit_size;
+#endif
 
 void bpf_jit_compile(struct bpf_prog *fp)
 {
@@ -1007,8 +1020,10 @@ void bpf_jit_compile(struct bpf_prog *fp)
 	unsigned alloc_size;
 	u8 *target_ptr;
 
+#ifdef __BPF_TEST
 	if (!bpf_jit_enable)
 		return;
+#endif
 
 	memset(&ctx, 0, sizeof(ctx));
 	ctx.skf		= fp;
@@ -1068,6 +1083,10 @@ void bpf_jit_compile(struct bpf_prog *fp)
 		kfree(ctx.imms);
 #endif
 
+#ifdef __BPF_TEST
+	bpf_emit_size = alloc_size;
+#endif
+
 	if (bpf_jit_enable > 1)
 		/* there are 2 passes here */
 		bpf_jit_dump(fp->len, alloc_size, 2, ctx.target);
diff --git a/arch/arm64/kernel/insn.c b/arch/arm64/kernel/insn.c
index c08b9ad6f429..088b45432b76 100644
--- a/arch/arm64/kernel/insn.c
+++ b/arch/arm64/kernel/insn.c
@@ -16,6 +16,9 @@
  * You should have received a copy of the GNU General Public License
  * along with this program.  If not, see <http://www.gnu.org/licenses/>.
  */
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/bitops.h>
 #include <linux/bug.h>
 #include <linux/compiler.h>
diff --git a/arch/arm64/net/bpf_jit_comp.c b/arch/arm64/net/bpf_jit_comp.c
index b162ad70effc..9d0cbd3b23eb 100644
--- a/arch/arm64/net/bpf_jit_comp.c
+++ b/arch/arm64/net/bpf_jit_comp.c
@@ -18,6 +18,9 @@
 
 #define pr_fmt(fmt) "bpf_jit: " fmt
 
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/filter.h>
 #include <linux/printk.h>
 #include <linux/skbuff.h>
@@ -31,6 +34,14 @@
 
 int bpf_jit_enable __read_mostly;
 
+#ifdef __aarch64__
+#define bpf_call_base __bpf_call_base
+#define realbpf_load_pointer bpf_load_pointer
+#else
+extern u8 bpf_call_base[];
+extern u8 realbpf_load_pointer[];
+#endif
+
 #define TMP_REG_1 (MAX_BPF_REG + 0)
 #define TMP_REG_2 (MAX_BPF_REG + 1)
 
@@ -519,7 +530,7 @@ emit_cond_jmp:
 	case BPF_JMP | BPF_CALL:
 	{
 		const u8 r0 = bpf2a64[BPF_REG_0];
-		const u64 func = (u64)__bpf_call_base + imm;
+		const u64 func = (u64)bpf_call_base + imm;
 
 		ctx->tmp_used = 1;
 		emit_a64_mov_i64(tmp, func, ctx);
@@ -676,7 +687,7 @@ emit_cond_jmp:
 		}
 		emit_a64_mov_i64(r3, size, ctx);
 		emit(A64_SUB_I(1, r4, fp, STACK_SIZE), ctx);
-		emit_a64_mov_i64(r5, (unsigned long)bpf_load_pointer, ctx);
+		emit_a64_mov_i64(r5, (unsigned long)realbpf_load_pointer, ctx);
 		emit(A64_PUSH(A64_FP, A64_LR, A64_SP), ctx);
 		emit(A64_MOV(1, A64_FP, A64_SP), ctx);
 		emit(A64_BLR(r5), ctx);
@@ -753,6 +764,10 @@ void bpf_jit_compile(struct bpf_prog *prog)
 	/* Nothing to do here. We support Internal BPF. */
 }
 
+#ifdef __BPF_TEST
+size_t bpf_emit_size;
+#endif
+
 void bpf_int_jit_compile(struct bpf_prog *prog)
 {
 	struct bpf_binary_header *header;
@@ -809,6 +824,7 @@ void bpf_int_jit_compile(struct bpf_prog *prog)
 	if (bpf_jit_enable > 1)
 		bpf_jit_dump(prog->len, image_size, 2, ctx.image);
 
+	bpf_emit_size = sizeof(*ctx.image) * ctx.idx;
 	bpf_flush_icache(header, ctx.image + ctx.idx);
 
 	set_memory_ro((unsigned long)header, header->pages);
diff --git a/arch/x86/net/bpf_jit_comp.c b/arch/x86/net/bpf_jit_comp.c
index 75991979f667..80c1af7eab2b 100644
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@ -8,6 +8,9 @@
  * as published by the Free Software Foundation; version 2
  * of the License.
  */
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/netdevice.h>
 #include <linux/filter.h>
 #include <linux/if_vlan.h>
@@ -1043,6 +1046,10 @@ void bpf_jit_compile(struct bpf_prog *prog)
 {
 }
 
+#ifdef __BPF_TEST
+size_t bpf_emit_size;
+#endif
+
 void bpf_int_jit_compile(struct bpf_prog *prog)
 {
 	struct bpf_binary_header *header = NULL;
@@ -1106,6 +1113,9 @@ void bpf_int_jit_compile(struct bpf_prog *prog)
 		bpf_jit_dump(prog->len, proglen, pass + 1, image);
 
 	if (image) {
+#ifdef __BPF_TEST
+		bpf_emit_size = proglen;
+#endif
 		bpf_flush_icache(header, image + proglen);
 		set_memory_ro((unsigned long)header, header->pages);
 		prog->bpf_func = (void *)image;
diff --git a/include/linux/filter.h b/include/linux/filter.h
index 4165e9ac9e36..804e8f221973 100644
--- a/include/linux/filter.h
+++ b/include/linux/filter.h
@@ -251,7 +251,15 @@ struct bpf_prog_aux;
 
 /* Function call */
 
-#define BPF_EMIT_CALL(FUNC)					\
+#define BPF_EMIT_CALL_RUNNER(FUNC)				\
+	((struct bpf_insn) {					\
+		.code  = BPF_JMP | BPF_CALL,			\
+		.dst_reg = 0,					\
+		.src_reg = 0,					\
+		.off   = 0,					\
+		.imm   = ((real ## FUNC) - real__bpf_call_base) })
+
+#define __BPF_EMIT_CALL(FUNC)					\
 	((struct bpf_insn) {					\
 		.code  = BPF_JMP | BPF_CALL,			\
 		.dst_reg = 0,					\
@@ -259,6 +267,14 @@ struct bpf_prog_aux;
 		.off   = 0,					\
 		.imm   = ((FUNC) - __bpf_call_base) })
 
+#ifdef __BPF_TEST_HOST
+#define BPF_EMIT_CALL(FUNC)					\
+	bpf_jit_enable ? BPF_EMIT_CALL_RUNNER(FUNC) :		\
+			 __BPF_EMIT_CALL(FUNC)
+#else
+#define BPF_EMIT_CALL(FUNC) __BPF_EMIT_CALL(FUNC)
+#endif
+
 /* Raw code statement block */
 
 #define BPF_RAW_INSN(CODE, DST, SRC, OFF, IMM)			\
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index 334b1bdd572c..441634256b5c 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -21,6 +21,9 @@
  * Kris Katterjohn - Added many additional checks in bpf_check_classic()
  */
 
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/filter.h>
 #include <linux/skbuff.h>
 #include <linux/vmalloc.h>
@@ -297,6 +300,10 @@ static unsigned int __bpf_prog_run(void *ctx, const struct bpf_insn *insn)
 		[BPF_LD | BPF_IMM | BPF_DW] = &&LD_IMM_DW,
 	};
 	u32 tail_call_cnt = 0;
+#ifdef ARCH_arm
+	u32 tmp32;
+	u64 tmp64;
+#endif
 	void *ptr;
 	int off;
 
@@ -332,11 +339,37 @@ select_insn:
 	ALU(SUB,  -)
 	ALU(AND,  &)
 	ALU(OR,   |)
+#if !defined(__BPF_TEST) || !defined(ARCH_arm)
 	ALU(LSH, <<)
 	ALU(RSH, >>)
+#endif
 	ALU(XOR,  ^)
 	ALU(MUL,  *)
 #undef ALU
+#ifdef ARCH_arm
+#define ALU_SHIFT(OPCODE, OP)			\
+	ALU64_##OPCODE##_X: 		\
+		tmp64 = SRC & 255u;	\
+		DST = tmp64 < 64 ? (DST OP tmp64) : 0;	\
+		CONT;			\
+	ALU_##OPCODE##_X: 		\
+		tmp32 = SRC & 255u;	\
+		DST = tmp32 < 32 ? ((u32) DST OP (u32) tmp32) : 0;	\
+		CONT;			\
+	ALU64_##OPCODE##_K: 		\
+		tmp64 = IMM & 255u;	\
+		DST = tmp64 < 64 ? (DST OP tmp64) : 0;		\
+		CONT;			\
+	ALU_##OPCODE##_K: 		\
+		tmp32 = IMM & 255u;	\
+		DST = tmp32 < 32 ? ((u32) DST OP (u32) tmp32) : 0;	\
+		CONT;
+
+	ALU_SHIFT(LSH, <<)
+	ALU_SHIFT(RSH, >>)
+#undef ALU_SHIFT
+#endif
+
 	ALU_NEG:
 		DST = (u32) -DST;
 		CONT;
diff --git a/net/core/filter.c b/net/core/filter.c
index 672eefbfbe99..08a1e7a374b8 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -21,6 +21,9 @@
  * Kris Katterjohn - Added many additional checks in bpf_check_classic()
  */
 
+#ifdef __BPF_TEST
+#include "compat.h"
+#endif
 #include <linux/module.h>
 #include <linux/types.h>
 #include <linux/mm.h>
